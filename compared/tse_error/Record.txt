C:\Users\apresekal\Anaconda3\envs\research\python.exe C:/Users/apresekal/code/dl-4-tsc/main_test_mod.py
2022-06-17 13:11:42.585825: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
(76199, 40)
(10, 38) 4
2022-06-17 13:11:44.998269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2022-06-17 13:11:45.041594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 387.49GiB/s
2022-06-17 13:11:45.041930: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2022-06-17 13:11:45.056629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2022-06-17 13:11:45.067481: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2022-06-17 13:11:45.071751: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2022-06-17 13:11:45.188507: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2022-06-17 13:11:45.197849: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2022-06-17 13:11:45.348285: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2022-06-17 13:11:45.348834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2022-06-17 13:11:45.350987: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-17 13:11:45.391943: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e259964100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-06-17 13:11:45.392641: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-06-17 13:11:45.394699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 387.49GiB/s
2022-06-17 13:11:45.395409: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2022-06-17 13:11:45.395789: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2022-06-17 13:11:45.396139: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2022-06-17 13:11:45.396494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2022-06-17 13:11:45.396849: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2022-06-17 13:11:45.397209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2022-06-17 13:11:45.397562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2022-06-17 13:11:45.397936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2022-06-17 13:11:46.664834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-17 13:11:46.665014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2022-06-17 13:11:46.665117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2022-06-17 13:11:46.666448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6627 MB memory) -> physical GPU (device: 0, name: Quadro RTX 4000, pci bus id: 0000:65:00.0, compute capability: 7.5)
2022-06-17 13:11:46.675371: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e20d2414e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-06-17 13:11:46.675591: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 4000, Compute Capability 7.5
Model: "functional_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 10, 38)]          0         
_________________________________________________________________
conv1d (Conv1D)              (None, 10, 6)             1602      
_________________________________________________________________
average_pooling1d (AveragePo (None, 3, 6)              0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 3, 12)             516       
_________________________________________________________________
average_pooling1d_1 (Average (None, 1, 12)             0         
_________________________________________________________________
flatten (Flatten)            (None, 12)                0         
_________________________________________________________________
dense (Dense)                (None, 4)                 52        
=================================================================
Total params: 2,170
Trainable params: 2,170
Non-trainable params: 0
_________________________________________________________________
None
2022-06-17 13:11:47.011614: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2022-06-17 13:11:47.012954: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs
2022-06-17 13:11:47.019110: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cupti64_101.dll'; dlerror: cupti64_101.dll not found
2022-06-17 13:11:47.022564: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cupti.dll'; dlerror: cupti.dll not found
2022-06-17 13:11:47.022764: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
Epoch 1/100
2022-06-17 13:11:47.773251: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2022-06-17 13:11:48.129704: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2022-06-17 13:11:50.609482: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
   1/1667 [..............................] - ETA: 0s - loss: 0.3431 - accuracy: 0.03122022-06-17 13:11:50.719901: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2022-06-17 13:11:50.720291: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
WARNING:tensorflow:From C:\Users\apresekal\Anaconda3\envs\research\lib\site-packages\tensorflow\python\ops\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
Instructions for updating:
use `tf.profiler.experimental.stop` instead.
2022-06-17 13:11:50.740100: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 0 callback api events and 0 activity events. 
2022-06-17 13:11:50.755013: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/cnn\train\plugins\profile\2022_06_17_11_11_50
2022-06-17 13:11:50.759730: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to C:\Users\apresekal\code\dl-4-tsc\out\logs/cnn\train\plugins\profile\2022_06_17_11_11_50\TUD278848.trace.json.gz
   2/1667 [..............................] - ETA: 57s - loss: 0.3439 - accuracy: 0.01562022-06-17 13:11:50.785450: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/cnn\train\plugins\profile\2022_06_17_11_11_50
2022-06-17 13:11:50.788957: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to C:\Users\apresekal\code\dl-4-tsc\out\logs/cnn\train\plugins\profile\2022_06_17_11_11_50\TUD278848.memory_profile.json.gz
2022-06-17 13:11:50.795711: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/cnn\train\plugins\profile\2022_06_17_11_11_50Dumped tool data for xplane.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/cnn\train\plugins\profile\2022_06_17_11_11_50\TUD278848.xplane.pb
Dumped tool data for overview_page.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/cnn\train\plugins\profile\2022_06_17_11_11_50\TUD278848.overview_page.pb
Dumped tool data for input_pipeline.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/cnn\train\plugins\profile\2022_06_17_11_11_50\TUD278848.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/cnn\train\plugins\profile\2022_06_17_11_11_50\TUD278848.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/cnn\train\plugins\profile\2022_06_17_11_11_50\TUD278848.kernel_stats.pb

WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0693s). Check your callbacks.
1667/1667 [==============================] - 6s 4ms/step - loss: 0.0353 - accuracy: 0.9461 - val_loss: 0.3707 - val_accuracy: 0.1903
Epoch 2/100
1667/1667 [==============================] - 6s 4ms/step - loss: 0.0106 - accuracy: 0.9789 - val_loss: 0.3855 - val_accuracy: 0.1903
Epoch 3/100
1667/1667 [==============================] - 6s 4ms/step - loss: 0.0104 - accuracy: 0.9789 - val_loss: 0.3888 - val_accuracy: 0.1903
Epoch 4/100
1667/1667 [==============================] - 6s 4ms/step - loss: 0.0104 - accuracy: 0.9789 - val_loss: 0.3897 - val_accuracy: 0.1903
Epoch 5/100
1667/1667 [==============================] - 6s 4ms/step - loss: 0.0104 - accuracy: 0.9789 - val_loss: 0.3878 - val_accuracy: 0.1903
Epoch 6/100
1667/1667 [==============================] - 7s 4ms/step - loss: 0.0103 - accuracy: 0.9789 - val_loss: 0.3861 - val_accuracy: 0.1903
Epoch 7/100
1667/1667 [==============================] - 6s 4ms/step - loss: 0.0067 - accuracy: 0.9852 - val_loss: 0.0143 - val_accuracy: 0.9863
Epoch 8/100
1667/1667 [==============================] - 6s 4ms/step - loss: 0.0016 - accuracy: 0.9970 - val_loss: 0.0079 - val_accuracy: 0.9863
Epoch 9/100
1667/1667 [==============================] - 7s 4ms/step - loss: 0.0013 - accuracy: 0.9971 - val_loss: 0.0072 - val_accuracy: 0.9863
Epoch 10/100
1667/1667 [==============================] - 6s 4ms/step - loss: 0.0011 - accuracy: 0.9976 - val_loss: 0.0070 - val_accuracy: 0.9863
Epoch 11/100
1667/1667 [==============================] - 6s 4ms/step - loss: 9.0850e-04 - accuracy: 0.9982 - val_loss: 0.0069 - val_accuracy: 0.9863
Epoch 12/100
1667/1667 [==============================] - 6s 3ms/step - loss: 8.3233e-04 - accuracy: 0.9983 - val_loss: 0.0089 - val_accuracy: 0.9859
Epoch 13/100
1667/1667 [==============================] - 6s 4ms/step - loss: 8.0916e-04 - accuracy: 0.9983 - val_loss: 0.0086 - val_accuracy: 0.9855
Epoch 14/100
1667/1667 [==============================] - 7s 4ms/step - loss: 7.9720e-04 - accuracy: 0.9983 - val_loss: 0.0088 - val_accuracy: 0.9850
Epoch 15/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.8508e-04 - accuracy: 0.9983 - val_loss: 0.0082 - val_accuracy: 0.9855
Epoch 16/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.7930e-04 - accuracy: 0.9983 - val_loss: 0.0083 - val_accuracy: 0.9853
Epoch 17/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.7446e-04 - accuracy: 0.9983 - val_loss: 0.0086 - val_accuracy: 0.9849
Epoch 18/100
1667/1667 [==============================] - 7s 4ms/step - loss: 7.6819e-04 - accuracy: 0.9984 - val_loss: 0.0092 - val_accuracy: 0.9842
Epoch 19/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.6310e-04 - accuracy: 0.9984 - val_loss: 0.0095 - val_accuracy: 0.9837
Epoch 20/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.5666e-04 - accuracy: 0.9984 - val_loss: 0.0095 - val_accuracy: 0.9836
Epoch 21/100
1667/1667 [==============================] - 7s 4ms/step - loss: 7.6025e-04 - accuracy: 0.9983 - val_loss: 0.0095 - val_accuracy: 0.9832
Epoch 22/100
1667/1667 [==============================] - 7s 4ms/step - loss: 7.5346e-04 - accuracy: 0.9984 - val_loss: 0.0094 - val_accuracy: 0.9833
Epoch 23/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.5333e-04 - accuracy: 0.9984 - val_loss: 0.0093 - val_accuracy: 0.9832
Epoch 24/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.5273e-04 - accuracy: 0.9984 - val_loss: 0.0100 - val_accuracy: 0.9827
Epoch 25/100
1667/1667 [==============================] - 7s 4ms/step - loss: 7.4698e-04 - accuracy: 0.9984 - val_loss: 0.0108 - val_accuracy: 0.9830
Epoch 26/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.4450e-04 - accuracy: 0.9984 - val_loss: 0.0109 - val_accuracy: 0.9821
Epoch 27/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.2737e-04 - accuracy: 0.9984 - val_loss: 0.0124 - val_accuracy: 0.9811
Epoch 28/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.8851e-04 - accuracy: 0.9984 - val_loss: 0.0172 - val_accuracy: 0.9804
Epoch 29/100
1667/1667 [==============================] - 6s 4ms/step - loss: 5.9365e-04 - accuracy: 0.9984 - val_loss: 0.0253 - val_accuracy: 0.9792
Epoch 30/100
1667/1667 [==============================] - 6s 4ms/step - loss: 4.3182e-04 - accuracy: 0.9985 - val_loss: 0.0524 - val_accuracy: 0.7185
Epoch 31/100
1667/1667 [==============================] - 6s 4ms/step - loss: 3.2744e-04 - accuracy: 0.9997 - val_loss: 0.0654 - val_accuracy: 0.7217
Epoch 32/100
1667/1667 [==============================] - 6s 4ms/step - loss: 2.5557e-04 - accuracy: 0.9997 - val_loss: 0.0808 - val_accuracy: 0.7211
Epoch 33/100
1667/1667 [==============================] - 6s 4ms/step - loss: 2.0190e-04 - accuracy: 0.9998 - val_loss: 0.0906 - val_accuracy: 0.7217
Epoch 34/100
1667/1667 [==============================] - 6s 4ms/step - loss: 1.6269e-04 - accuracy: 0.9998 - val_loss: 0.1047 - val_accuracy: 0.7193
Epoch 35/100
1667/1667 [==============================] - 6s 4ms/step - loss: 1.3188e-04 - accuracy: 0.9998 - val_loss: 0.1140 - val_accuracy: 0.7181
Epoch 36/100
1667/1667 [==============================] - 7s 4ms/step - loss: 1.1872e-04 - accuracy: 0.9998 - val_loss: 0.1131 - val_accuracy: 0.7221
Epoch 37/100
1667/1667 [==============================] - 7s 4ms/step - loss: 1.0624e-04 - accuracy: 0.9998 - val_loss: 0.1201 - val_accuracy: 0.7217
Epoch 38/100
1667/1667 [==============================] - 6s 4ms/step - loss: 9.9362e-05 - accuracy: 0.9998 - val_loss: 0.1224 - val_accuracy: 0.7218
Epoch 39/100
1667/1667 [==============================] - 6s 4ms/step - loss: 9.7923e-05 - accuracy: 0.9998 - val_loss: 0.1266 - val_accuracy: 0.7206
Epoch 40/100
1667/1667 [==============================] - 6s 4ms/step - loss: 9.1160e-05 - accuracy: 0.9998 - val_loss: 0.1268 - val_accuracy: 0.7215
Epoch 41/100
1667/1667 [==============================] - 6s 4ms/step - loss: 8.5467e-05 - accuracy: 0.9998 - val_loss: 0.1301 - val_accuracy: 0.7214
Epoch 42/100
1667/1667 [==============================] - 6s 4ms/step - loss: 8.6072e-05 - accuracy: 0.9998 - val_loss: 0.1301 - val_accuracy: 0.7219
Epoch 43/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.9104e-05 - accuracy: 0.9998 - val_loss: 0.1310 - val_accuracy: 0.7216
Epoch 44/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.9674e-05 - accuracy: 0.9998 - val_loss: 0.1328 - val_accuracy: 0.7211
Epoch 45/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.8887e-05 - accuracy: 0.9998 - val_loss: 0.1330 - val_accuracy: 0.7216
Epoch 46/100
1667/1667 [==============================] - 7s 4ms/step - loss: 7.8802e-05 - accuracy: 0.9998 - val_loss: 0.1336 - val_accuracy: 0.7214
Epoch 47/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.9736e-05 - accuracy: 0.9998 - val_loss: 0.1340 - val_accuracy: 0.7218
Epoch 48/100
1667/1667 [==============================] - 7s 4ms/step - loss: 7.7978e-05 - accuracy: 0.9998 - val_loss: 0.1337 - val_accuracy: 0.7215
Epoch 49/100
1667/1667 [==============================] - 7s 4ms/step - loss: 8.0057e-05 - accuracy: 0.9998 - val_loss: 0.1340 - val_accuracy: 0.7218
Epoch 50/100
1667/1667 [==============================] - 6s 4ms/step - loss: 8.6008e-05 - accuracy: 0.9998 - val_loss: 0.1347 - val_accuracy: 0.7216
Epoch 51/100
1667/1667 [==============================] - 7s 4ms/step - loss: 7.6719e-05 - accuracy: 0.9998 - val_loss: 0.1348 - val_accuracy: 0.7217
Epoch 52/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.3609e-05 - accuracy: 0.9998 - val_loss: 0.1351 - val_accuracy: 0.7214
Epoch 53/100
1667/1667 [==============================] - 6s 3ms/step - loss: 7.5996e-05 - accuracy: 0.9998 - val_loss: 0.1356 - val_accuracy: 0.7211
Epoch 54/100
1667/1667 [==============================] - 6s 3ms/step - loss: 7.3443e-05 - accuracy: 0.9998 - val_loss: 0.1357 - val_accuracy: 0.7214
Epoch 55/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.5094e-05 - accuracy: 0.9998 - val_loss: 0.1356 - val_accuracy: 0.7216
Epoch 56/100
1667/1667 [==============================] - 6s 3ms/step - loss: 7.2572e-05 - accuracy: 0.9998 - val_loss: 0.1359 - val_accuracy: 0.7217
Epoch 57/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.1015e-05 - accuracy: 0.9998 - val_loss: 0.1363 - val_accuracy: 0.7215
Epoch 58/100
1667/1667 [==============================] - 7s 4ms/step - loss: 7.1639e-05 - accuracy: 0.9998 - val_loss: 0.1364 - val_accuracy: 0.7215
Epoch 59/100
1667/1667 [==============================] - 7s 4ms/step - loss: 6.7893e-05 - accuracy: 0.9998 - val_loss: 0.1365 - val_accuracy: 0.7217
Epoch 60/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.9556e-05 - accuracy: 0.9998 - val_loss: 0.1369 - val_accuracy: 0.7211
Epoch 61/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.2190e-05 - accuracy: 0.9998 - val_loss: 0.1363 - val_accuracy: 0.7218
Epoch 62/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.6663e-05 - accuracy: 0.9998 - val_loss: 0.1368 - val_accuracy: 0.7214
Epoch 63/100
1667/1667 [==============================] - 7s 4ms/step - loss: 6.9790e-05 - accuracy: 0.9999 - val_loss: 0.1367 - val_accuracy: 0.7217
Epoch 64/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.9467e-05 - accuracy: 0.9998 - val_loss: 0.1368 - val_accuracy: 0.7216
Epoch 65/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.0820e-05 - accuracy: 0.9999 - val_loss: 0.1370 - val_accuracy: 0.7216
Epoch 66/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.7327e-05 - accuracy: 0.9998 - val_loss: 0.1374 - val_accuracy: 0.7211
Epoch 67/100
1667/1667 [==============================] - 7s 4ms/step - loss: 6.7172e-05 - accuracy: 0.9998 - val_loss: 0.1376 - val_accuracy: 0.7211
Epoch 68/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.3020e-05 - accuracy: 0.9998 - val_loss: 0.1375 - val_accuracy: 0.7211
Epoch 69/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.4484e-05 - accuracy: 0.9998 - val_loss: 0.1374 - val_accuracy: 0.7214
Epoch 70/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.2330e-05 - accuracy: 0.9999 - val_loss: 0.1372 - val_accuracy: 0.7216
Epoch 71/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.6270e-05 - accuracy: 0.9999 - val_loss: 0.1378 - val_accuracy: 0.7210
Epoch 72/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.1761e-05 - accuracy: 0.9999 - val_loss: 0.1375 - val_accuracy: 0.7216
Epoch 73/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.3412e-05 - accuracy: 0.9999 - val_loss: 0.1374 - val_accuracy: 0.7218
Epoch 74/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.1920e-05 - accuracy: 0.9998 - val_loss: 0.1377 - val_accuracy: 0.7214
Epoch 75/100
1667/1667 [==============================] - 6s 4ms/step - loss: 5.8556e-05 - accuracy: 0.9999 - val_loss: 0.1380 - val_accuracy: 0.7213
Epoch 76/100
1667/1667 [==============================] - 7s 4ms/step - loss: 6.2229e-05 - accuracy: 0.9999 - val_loss: 0.1385 - val_accuracy: 0.7202
Epoch 77/100
1667/1667 [==============================] - 7s 4ms/step - loss: 6.5312e-05 - accuracy: 0.9998 - val_loss: 0.1379 - val_accuracy: 0.7214
Epoch 78/100
1667/1667 [==============================] - 7s 4ms/step - loss: 6.1774e-05 - accuracy: 0.9999 - val_loss: 0.1378 - val_accuracy: 0.7216
Epoch 79/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.5673e-05 - accuracy: 0.9998 - val_loss: 0.1380 - val_accuracy: 0.7212
Epoch 80/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.0062e-05 - accuracy: 0.9999 - val_loss: 0.1377 - val_accuracy: 0.7215
Epoch 81/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.4392e-05 - accuracy: 0.9999 - val_loss: 0.1381 - val_accuracy: 0.7211
Epoch 82/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.0877e-05 - accuracy: 0.9999 - val_loss: 0.1382 - val_accuracy: 0.7212
Epoch 83/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.5867e-05 - accuracy: 0.9998 - val_loss: 0.1384 - val_accuracy: 0.7210
Epoch 84/100
1667/1667 [==============================] - 6s 4ms/step - loss: 5.5844e-05 - accuracy: 0.9999 - val_loss: 0.1381 - val_accuracy: 0.7214
Epoch 85/100
1667/1667 [==============================] - 6s 4ms/step - loss: 5.8638e-05 - accuracy: 0.9999 - val_loss: 0.1383 - val_accuracy: 0.7212
Epoch 86/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.2788e-05 - accuracy: 0.9999 - val_loss: 0.1385 - val_accuracy: 0.7210
Epoch 87/100
1667/1667 [==============================] - 7s 4ms/step - loss: 7.2802e-05 - accuracy: 0.9998 - val_loss: 0.1379 - val_accuracy: 0.7218
Epoch 88/100
1667/1667 [==============================] - 7s 4ms/step - loss: 6.7107e-05 - accuracy: 0.9998 - val_loss: 0.1400 - val_accuracy: 0.7171
Epoch 89/100
1667/1667 [==============================] - 7s 4ms/step - loss: 6.1396e-05 - accuracy: 0.9998 - val_loss: 0.1384 - val_accuracy: 0.7212
Epoch 90/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.4229e-05 - accuracy: 0.9998 - val_loss: 0.1384 - val_accuracy: 0.7211
Epoch 91/100
1667/1667 [==============================] - 6s 4ms/step - loss: 5.5651e-05 - accuracy: 0.9999 - val_loss: 0.1414 - val_accuracy: 0.7137
Epoch 92/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.0950e-05 - accuracy: 0.9999 - val_loss: 0.1386 - val_accuracy: 0.7210
Epoch 93/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.3136e-05 - accuracy: 0.9998 - val_loss: 0.1386 - val_accuracy: 0.7210
Epoch 94/100
1667/1667 [==============================] - 7s 4ms/step - loss: 6.0570e-05 - accuracy: 0.9999 - val_loss: 0.1389 - val_accuracy: 0.7200
Epoch 95/100
1667/1667 [==============================] - 7s 4ms/step - loss: 5.9512e-05 - accuracy: 0.9999 - val_loss: 0.1386 - val_accuracy: 0.7210
Epoch 96/100
1667/1667 [==============================] - 6s 4ms/step - loss: 7.1175e-05 - accuracy: 0.9998 - val_loss: 0.1389 - val_accuracy: 0.7201
Epoch 97/100
1667/1667 [==============================] - 7s 4ms/step - loss: 5.9103e-05 - accuracy: 0.9999 - val_loss: 0.1383 - val_accuracy: 0.7215
Epoch 98/100
1667/1667 [==============================] - 6s 4ms/step - loss: 6.0941e-05 - accuracy: 0.9999 - val_loss: 0.1388 - val_accuracy: 0.7206
Epoch 99/100
1667/1667 [==============================] - 6s 4ms/step - loss: 5.8416e-05 - accuracy: 0.9999 - val_loss: 0.1389 - val_accuracy: 0.7203
Epoch 100/100
1667/1667 [==============================] - 6s 4ms/step - loss: 5.9344e-05 - accuracy: 0.9999 - val_loss: 0.1387 - val_accuracy: 0.7212
WARNING:tensorflow:From C:\Users\apresekal\Anaconda3\envs\research\lib\site-packages\tensorflow\python\training\tracking\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2022-06-17 13:22:27.088197: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From C:\Users\apresekal\Anaconda3\envs\research\lib\site-packages\tensorflow\python\training\tracking\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
Model: "functional_3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 10, 38)]     0                                            
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 10, 64)       19520       input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 10, 64)       256         conv1d_2[0][0]                   
__________________________________________________________________________________________________
activation (Activation)         (None, 10, 64)       0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 10, 64)       20544       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 10, 64)       256         conv1d_3[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 10, 64)       0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 10, 64)       2496        input_2[0][0]                    
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 10, 64)       12352       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 10, 64)       256         conv1d_5[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 10, 64)       256         conv1d_4[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 10, 64)       0           batch_normalization_3[0][0]      
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 10, 64)       0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 10, 128)      65664       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 10, 128)      512         conv1d_6[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 10, 128)      0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 10, 128)      82048       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 10, 128)      512         conv1d_7[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 10, 128)      0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 10, 128)      8320        activation_2[0][0]               
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 10, 128)      49280       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 10, 128)      512         conv1d_9[0][0]                   
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 10, 128)      512         conv1d_8[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 10, 128)      0           batch_normalization_7[0][0]      
                                                                 batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 10, 128)      0           add_1[0][0]                      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 10, 128)      131200      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 10, 128)      512         conv1d_10[0][0]                  
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 10, 128)      0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv1d_11 (Conv1D)              (None, 10, 128)      82048       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 10, 128)      512         conv1d_11[0][0]                  
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 10, 128)      0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv1d_12 (Conv1D)              (None, 10, 128)      49280       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 10, 128)      512         activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 10, 128)      512         conv1d_12[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 10, 128)      0           batch_normalization_11[0][0]     
                                                                 batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 10, 128)      0           add_2[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 128)          0           activation_8[0][0]               
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 4)            516         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 528,388
Trainable params: 525,828
Non-trainable params: 2,560
__________________________________________________________________________________________________
None
2022-06-17 13:22:28.058748: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2022-06-17 13:22:28.059187: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
Epoch 1/100
   1/1667 [..............................] - ETA: 0s - loss: 3.0804 - accuracy: 0.0000e+002022-06-17 13:22:31.438642: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2022-06-17 13:22:31.439071: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2022-06-17 13:22:31.670402: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 0 callback api events and 0 activity events. 
2022-06-17 13:22:31.676053: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/resnet\train\plugins\profile\2022_06_17_11_22_31
2022-06-17 13:22:31.679741: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to C:\Users\apresekal\code\dl-4-tsc\out\logs/resnet\train\plugins\profile\2022_06_17_11_22_31\TUD278848.trace.json.gz
2022-06-17 13:22:31.734872: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/resnet\train\plugins\profile\2022_06_17_11_22_31
2022-06-17 13:22:31.742173: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to C:\Users\apresekal\code\dl-4-tsc\out\logs/resnet\train\plugins\profile\2022_06_17_11_22_31\TUD278848.memory_profile.json.gz
   2/1667 [..............................] - ETA: 4:22 - loss: 2.5991 - accuracy: 0.0000e+002022-06-17 13:22:31.750049: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/resnet\train\plugins\profile\2022_06_17_11_22_31Dumped tool data for xplane.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/resnet\train\plugins\profile\2022_06_17_11_22_31\TUD278848.xplane.pb
Dumped tool data for overview_page.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/resnet\train\plugins\profile\2022_06_17_11_22_31\TUD278848.overview_page.pb
Dumped tool data for input_pipeline.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/resnet\train\plugins\profile\2022_06_17_11_22_31\TUD278848.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/resnet\train\plugins\profile\2022_06_17_11_22_31\TUD278848.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/resnet\train\plugins\profile\2022_06_17_11_22_31\TUD278848.kernel_stats.pb

WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0153s vs `on_train_batch_end` time: 0.3005s). Check your callbacks.
1667/1667 [==============================] - 32s 19ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 13.9025 - val_accuracy: 0.3091
Epoch 2/100
1667/1667 [==============================] - 26s 16ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 4.0442 - val_accuracy: 0.8049
Epoch 3/100
1667/1667 [==============================] - 28s 17ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 3.7297 - val_accuracy: 0.8382
Epoch 4/100
1667/1667 [==============================] - 30s 18ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 16.8575 - val_accuracy: 0.8025
Epoch 5/100
1667/1667 [==============================] - 28s 17ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 8.8172 - val_accuracy: 0.8153
Epoch 6/100
1667/1667 [==============================] - 30s 18ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 2.1513 - val_accuracy: 0.8585
Epoch 7/100
1667/1667 [==============================] - 32s 19ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 14.2118 - val_accuracy: 0.7980
Epoch 8/100
1667/1667 [==============================] - 30s 18ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 9.5170 - val_accuracy: 0.8157
Epoch 9/100
1667/1667 [==============================] - 25s 15ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 16.1548 - val_accuracy: 0.8079
Epoch 10/100
1667/1667 [==============================] - 32s 19ms/step - loss: 9.5742e-04 - accuracy: 0.9998 - val_loss: 4.0443 - val_accuracy: 0.8353
Epoch 11/100
1667/1667 [==============================] - 31s 19ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 14.0318 - val_accuracy: 0.7723
Epoch 12/100
1667/1667 [==============================] - 29s 18ms/step - loss: 9.3879e-04 - accuracy: 0.9999 - val_loss: 12.9900 - val_accuracy: 0.8082
Epoch 13/100
1667/1667 [==============================] - 30s 18ms/step - loss: 9.7848e-04 - accuracy: 0.9998 - val_loss: 41.3129 - val_accuracy: 0.7437
Epoch 14/100
1667/1667 [==============================] - 26s 15ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 33.7869 - val_accuracy: 0.7504
Epoch 15/100
1667/1667 [==============================] - 25s 15ms/step - loss: 8.9107e-04 - accuracy: 0.9999 - val_loss: 15.5180 - val_accuracy: 0.7718
Epoch 16/100
1667/1667 [==============================] - 22s 13ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 13.8664 - val_accuracy: 0.7994
Epoch 17/100
1667/1667 [==============================] - 22s 13ms/step - loss: 9.0623e-04 - accuracy: 0.9998 - val_loss: 38.0484 - val_accuracy: 0.7640
Epoch 18/100
1667/1667 [==============================] - 24s 15ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 21.8542 - val_accuracy: 0.7594
Epoch 19/100
1667/1667 [==============================] - 24s 14ms/step - loss: 9.7736e-04 - accuracy: 0.9998 - val_loss: 24.9036 - val_accuracy: 0.7347
Epoch 20/100
1667/1667 [==============================] - 23s 14ms/step - loss: 9.1218e-04 - accuracy: 0.9999 - val_loss: 17.4832 - val_accuracy: 0.7913
Epoch 21/100
1667/1667 [==============================] - 25s 15ms/step - loss: 8.3766e-04 - accuracy: 0.9999 - val_loss: 18.7203 - val_accuracy: 0.7915
Epoch 22/100
1667/1667 [==============================] - 25s 15ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 11.1023 - val_accuracy: 0.8387
Epoch 23/100
1667/1667 [==============================] - 24s 14ms/step - loss: 9.4129e-04 - accuracy: 0.9999 - val_loss: 26.4198 - val_accuracy: 0.7914
Epoch 24/100
1667/1667 [==============================] - 26s 15ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 33.6528 - val_accuracy: 0.7635
Epoch 25/100
1667/1667 [==============================] - 23s 14ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 15.1220 - val_accuracy: 0.7940
Epoch 26/100
1667/1667 [==============================] - 24s 14ms/step - loss: 8.5947e-04 - accuracy: 0.9999 - val_loss: 17.3681 - val_accuracy: 0.8146
Epoch 27/100
1667/1667 [==============================] - 24s 14ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 26.2149 - val_accuracy: 0.6700
Epoch 28/100
1667/1667 [==============================] - 31s 19ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 143.5202 - val_accuracy: 0.6458
Epoch 29/100
1667/1667 [==============================] - 27s 16ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 37.3353 - val_accuracy: 0.8137
Epoch 30/100
1667/1667 [==============================] - 23s 14ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 25.7109 - val_accuracy: 0.8239
Epoch 31/100
1667/1667 [==============================] - 23s 14ms/step - loss: 8.5940e-04 - accuracy: 0.9999 - val_loss: 43.2977 - val_accuracy: 0.8141
Epoch 32/100
1667/1667 [==============================] - 22s 13ms/step - loss: 9.2691e-04 - accuracy: 0.9998 - val_loss: 27.9014 - val_accuracy: 0.7653
Epoch 33/100
1667/1667 [==============================] - 22s 13ms/step - loss: 9.2347e-04 - accuracy: 0.9999 - val_loss: 23.4598 - val_accuracy: 0.7390
Epoch 34/100
1667/1667 [==============================] - 20s 12ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 37.9253 - val_accuracy: 0.6316
Epoch 35/100
1667/1667 [==============================] - 21s 13ms/step - loss: 9.8124e-04 - accuracy: 0.9998 - val_loss: 17.5170 - val_accuracy: 0.7561
Epoch 36/100
1667/1667 [==============================] - 21s 12ms/step - loss: 9.1068e-04 - accuracy: 0.9999 - val_loss: 14.3099 - val_accuracy: 0.8022
Epoch 37/100
1667/1667 [==============================] - 22s 13ms/step - loss: 8.3161e-04 - accuracy: 0.9998 - val_loss: 20.2573 - val_accuracy: 0.7959
Epoch 38/100
1667/1667 [==============================] - 19s 12ms/step - loss: 8.7365e-04 - accuracy: 0.9999 - val_loss: 17.8580 - val_accuracy: 0.8225
Epoch 39/100
1667/1667 [==============================] - 23s 14ms/step - loss: 8.7611e-04 - accuracy: 0.9998 - val_loss: 21.3914 - val_accuracy: 0.8170
Epoch 40/100
1667/1667 [==============================] - 20s 12ms/step - loss: 8.1515e-04 - accuracy: 0.9999 - val_loss: 13.3188 - val_accuracy: 0.8352
Epoch 41/100
1667/1667 [==============================] - 24s 14ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 23.6630 - val_accuracy: 0.7561
Epoch 42/100
1667/1667 [==============================] - 27s 16ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 34.1111 - val_accuracy: 0.7054
Epoch 43/100
1667/1667 [==============================] - 29s 18ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 34.2368 - val_accuracy: 0.7434
Epoch 44/100
1667/1667 [==============================] - 30s 18ms/step - loss: 8.7904e-04 - accuracy: 0.9999 - val_loss: 61.9181 - val_accuracy: 0.6678
Epoch 45/100
1667/1667 [==============================] - 31s 19ms/step - loss: 9.8286e-04 - accuracy: 0.9999 - val_loss: 18.4744 - val_accuracy: 0.8082
Epoch 46/100
1667/1667 [==============================] - 31s 19ms/step - loss: 9.0484e-04 - accuracy: 0.9999 - val_loss: 20.9198 - val_accuracy: 0.8129
Epoch 47/100
1667/1667 [==============================] - 31s 19ms/step - loss: 8.3974e-04 - accuracy: 0.9999 - val_loss: 42.9709 - val_accuracy: 0.6607
Epoch 48/100
1667/1667 [==============================] - 31s 18ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 28.4625 - val_accuracy: 0.6697
Epoch 49/100
1667/1667 [==============================] - 29s 18ms/step - loss: 8.8328e-04 - accuracy: 0.9999 - val_loss: 41.6616 - val_accuracy: 0.7026
Epoch 50/100
1667/1667 [==============================] - 30s 18ms/step - loss: 9.2721e-04 - accuracy: 0.9999 - val_loss: 95.8710 - val_accuracy: 0.6556
Epoch 51/100
1667/1667 [==============================] - 21s 12ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 35.5394 - val_accuracy: 0.6836
Epoch 52/100
1667/1667 [==============================] - 26s 16ms/step - loss: 9.0064e-04 - accuracy: 0.9999 - val_loss: 37.3256 - val_accuracy: 0.7077
Epoch 53/100
1667/1667 [==============================] - 24s 15ms/step - loss: 8.4030e-04 - accuracy: 0.9999 - val_loss: 36.3395 - val_accuracy: 0.7446
Epoch 54/100
1667/1667 [==============================] - 29s 17ms/step - loss: 8.6811e-04 - accuracy: 0.9999 - val_loss: 29.9267 - val_accuracy: 0.7757
Epoch 55/100
1667/1667 [==============================] - 31s 18ms/step - loss: 9.8986e-04 - accuracy: 0.9999 - val_loss: 53.7618 - val_accuracy: 0.7022
Epoch 56/100
1667/1667 [==============================] - 31s 19ms/step - loss: 8.7453e-04 - accuracy: 0.9999 - val_loss: 50.4597 - val_accuracy: 0.7303
Epoch 57/100
1667/1667 [==============================] - 30s 18ms/step - loss: 8.2767e-04 - accuracy: 0.9999 - val_loss: 54.2235 - val_accuracy: 0.6998
Epoch 58/100
1667/1667 [==============================] - 30s 18ms/step - loss: 8.7528e-04 - accuracy: 0.9999 - val_loss: 37.0279 - val_accuracy: 0.7343
Epoch 59/100
1667/1667 [==============================] - 30s 18ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 33.4590 - val_accuracy: 0.6827
Epoch 60/100
1667/1667 [==============================] - 31s 19ms/step - loss: 9.0777e-04 - accuracy: 0.9999 - val_loss: 38.0104 - val_accuracy: 0.6542
Epoch 61/100
1667/1667 [==============================] - 31s 19ms/step - loss: 8.1600e-04 - accuracy: 0.9999 - val_loss: 40.9909 - val_accuracy: 0.6505
Epoch 62/100
1667/1667 [==============================] - 31s 18ms/step - loss: 8.5024e-04 - accuracy: 0.9999 - val_loss: 54.5698 - val_accuracy: 0.6578
Epoch 63/100
1667/1667 [==============================] - 28s 17ms/step - loss: 8.4837e-04 - accuracy: 0.9999 - val_loss: 43.9594 - val_accuracy: 0.6869
Epoch 64/100
1667/1667 [==============================] - 32s 19ms/step - loss: 9.9179e-04 - accuracy: 0.9999 - val_loss: 75.2465 - val_accuracy: 0.6399
Epoch 65/100
1667/1667 [==============================] - 32s 19ms/step - loss: 8.9478e-04 - accuracy: 0.9999 - val_loss: 141.7975 - val_accuracy: 0.6293
Epoch 66/100
1667/1667 [==============================] - 32s 19ms/step - loss: 8.4105e-04 - accuracy: 0.9999 - val_loss: 231.8863 - val_accuracy: 0.3655
Epoch 67/100
1667/1667 [==============================] - 32s 19ms/step - loss: 9.1737e-04 - accuracy: 0.9999 - val_loss: 145.3030 - val_accuracy: 0.7375
Epoch 68/100
1667/1667 [==============================] - 31s 19ms/step - loss: 8.1730e-04 - accuracy: 0.9999 - val_loss: 126.6825 - val_accuracy: 0.6980
Epoch 69/100
1667/1667 [==============================] - 31s 19ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 257.8580 - val_accuracy: 0.5734
Epoch 70/100
1667/1667 [==============================] - 31s 19ms/step - loss: 8.0463e-04 - accuracy: 0.9999 - val_loss: 156.4485 - val_accuracy: 0.6501
Epoch 71/100
1667/1667 [==============================] - 30s 18ms/step - loss: 8.7322e-04 - accuracy: 0.9999 - val_loss: 231.4594 - val_accuracy: 0.6511
Epoch 72/100
1667/1667 [==============================] - 32s 19ms/step - loss: 9.1542e-04 - accuracy: 0.9999 - val_loss: 236.6951 - val_accuracy: 0.6365
Epoch 73/100
1667/1667 [==============================] - 31s 19ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 111.7924 - val_accuracy: 0.6409
Epoch 74/100
1667/1667 [==============================] - 31s 19ms/step - loss: 8.0453e-04 - accuracy: 0.9999 - val_loss: 110.6022 - val_accuracy: 0.6279
Epoch 75/100
1667/1667 [==============================] - 32s 19ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 76.8689 - val_accuracy: 0.6846
Epoch 76/100
1667/1667 [==============================] - 32s 19ms/step - loss: 8.5286e-04 - accuracy: 0.9999 - val_loss: 64.0176 - val_accuracy: 0.6841
Epoch 77/100
1667/1667 [==============================] - 32s 19ms/step - loss: 8.6302e-04 - accuracy: 0.9999 - val_loss: 68.2433 - val_accuracy: 0.6261
Epoch 78/100
1667/1667 [==============================] - 31s 18ms/step - loss: 8.4245e-04 - accuracy: 0.9999 - val_loss: 61.1938 - val_accuracy: 0.6017
Epoch 79/100
1667/1667 [==============================] - 28s 17ms/step - loss: 9.6311e-04 - accuracy: 0.9999 - val_loss: 68.5553 - val_accuracy: 0.7664
Epoch 80/100
1667/1667 [==============================] - 30s 18ms/step - loss: 8.5796e-04 - accuracy: 0.9999 - val_loss: 95.4923 - val_accuracy: 0.7295
Epoch 81/100
1667/1667 [==============================] - 32s 19ms/step - loss: 7.6499e-04 - accuracy: 0.9999 - val_loss: 75.4431 - val_accuracy: 0.7718
Epoch 82/100
1667/1667 [==============================] - 30s 18ms/step - loss: 8.3880e-04 - accuracy: 0.9999 - val_loss: 73.2209 - val_accuracy: 0.7651
Epoch 83/100
1667/1667 [==============================] - 30s 18ms/step - loss: 9.0570e-04 - accuracy: 0.9999 - val_loss: 105.4305 - val_accuracy: 0.7444
Epoch 84/100
1667/1667 [==============================] - 31s 19ms/step - loss: 9.9851e-04 - accuracy: 0.9999 - val_loss: 230.0720 - val_accuracy: 0.4594
Epoch 85/100
1667/1667 [==============================] - 32s 19ms/step - loss: 9.4335e-04 - accuracy: 0.9999 - val_loss: 437.9123 - val_accuracy: 0.3776
Epoch 86/100
1667/1667 [==============================] - 31s 19ms/step - loss: 8.8697e-04 - accuracy: 0.9999 - val_loss: 199.3797 - val_accuracy: 0.5666
Epoch 87/100
1667/1667 [==============================] - 30s 18ms/step - loss: 8.6245e-04 - accuracy: 0.9999 - val_loss: 75.7287 - val_accuracy: 0.6299
Epoch 88/100
1667/1667 [==============================] - 32s 19ms/step - loss: 8.7892e-04 - accuracy: 0.9999 - val_loss: 113.0777 - val_accuracy: 0.6064
Epoch 89/100
1667/1667 [==============================] - 30s 18ms/step - loss: 8.5859e-04 - accuracy: 0.9999 - val_loss: 65.9117 - val_accuracy: 0.6042
Epoch 90/100
1667/1667 [==============================] - 31s 18ms/step - loss: 8.6698e-04 - accuracy: 0.9999 - val_loss: 54.2163 - val_accuracy: 0.5771
Epoch 91/100
1667/1667 [==============================] - 31s 19ms/step - loss: 8.6914e-04 - accuracy: 0.9999 - val_loss: 68.7867 - val_accuracy: 0.4914
Epoch 92/100
1667/1667 [==============================] - 32s 19ms/step - loss: 8.9398e-04 - accuracy: 0.9999 - val_loss: 61.9483 - val_accuracy: 0.5143
Epoch 93/100
1667/1667 [==============================] - 31s 18ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 55.9024 - val_accuracy: 0.5209
Epoch 94/100
1667/1667 [==============================] - 31s 19ms/step - loss: 8.0613e-04 - accuracy: 0.9999 - val_loss: 63.0259 - val_accuracy: 0.5294
Epoch 95/100
1667/1667 [==============================] - 32s 19ms/step - loss: 8.0778e-04 - accuracy: 0.9999 - val_loss: 55.1381 - val_accuracy: 0.5593
Epoch 96/100
1667/1667 [==============================] - 31s 19ms/step - loss: 8.7013e-04 - accuracy: 0.9999 - val_loss: 51.8536 - val_accuracy: 0.5526
Epoch 97/100
1667/1667 [==============================] - 33s 20ms/step - loss: 8.8034e-04 - accuracy: 0.9999 - val_loss: 75.5458 - val_accuracy: 0.5290
Epoch 98/100
1667/1667 [==============================] - 29s 18ms/step - loss: 9.5941e-04 - accuracy: 0.9999 - val_loss: 51.7044 - val_accuracy: 0.5954
Epoch 99/100
1667/1667 [==============================] - 34s 20ms/step - loss: 8.2032e-04 - accuracy: 0.9999 - val_loss: 63.5955 - val_accuracy: 0.5289
Epoch 100/100
1667/1667 [==============================] - 33s 20ms/step - loss: 8.1412e-04 - accuracy: 0.9999 - val_loss: 77.6752 - val_accuracy: 0.5174
Model: "functional_7"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            [(None, 10, 38)]     0                                            
__________________________________________________________________________________________________
conv1d_45 (Conv1D)              (None, 10, 32)       1216        input_4[0][0]                    
__________________________________________________________________________________________________
max_pooling1d_6 (MaxPooling1D)  (None, 10, 38)       0           input_4[0][0]                    
__________________________________________________________________________________________________
conv1d_46 (Conv1D)              (None, 10, 32)       40960       conv1d_45[0][0]                  
__________________________________________________________________________________________________
conv1d_47 (Conv1D)              (None, 10, 32)       20480       conv1d_45[0][0]                  
__________________________________________________________________________________________________
conv1d_48 (Conv1D)              (None, 10, 32)       10240       conv1d_45[0][0]                  
__________________________________________________________________________________________________
conv1d_49 (Conv1D)              (None, 10, 32)       1216        max_pooling1d_6[0][0]            
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 10, 128)      0           conv1d_46[0][0]                  
                                                                 conv1d_47[0][0]                  
                                                                 conv1d_48[0][0]                  
                                                                 conv1d_49[0][0]                  
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 10, 128)      512         concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 10, 128)      0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv1d_50 (Conv1D)              (None, 10, 32)       4096        activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling1d_7 (MaxPooling1D)  (None, 10, 128)      0           activation_17[0][0]              
__________________________________________________________________________________________________
conv1d_51 (Conv1D)              (None, 10, 32)       40960       conv1d_50[0][0]                  
__________________________________________________________________________________________________
conv1d_52 (Conv1D)              (None, 10, 32)       20480       conv1d_50[0][0]                  
__________________________________________________________________________________________________
conv1d_53 (Conv1D)              (None, 10, 32)       10240       conv1d_50[0][0]                  
__________________________________________________________________________________________________
conv1d_54 (Conv1D)              (None, 10, 32)       4096        max_pooling1d_7[0][0]            
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 10, 128)      0           conv1d_51[0][0]                  
                                                                 conv1d_52[0][0]                  
                                                                 conv1d_53[0][0]                  
                                                                 conv1d_54[0][0]                  
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 10, 128)      512         concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 10, 128)      0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
conv1d_55 (Conv1D)              (None, 10, 32)       4096        activation_18[0][0]              
__________________________________________________________________________________________________
max_pooling1d_8 (MaxPooling1D)  (None, 10, 128)      0           activation_18[0][0]              
__________________________________________________________________________________________________
conv1d_56 (Conv1D)              (None, 10, 32)       40960       conv1d_55[0][0]                  
__________________________________________________________________________________________________
conv1d_57 (Conv1D)              (None, 10, 32)       20480       conv1d_55[0][0]                  
__________________________________________________________________________________________________
conv1d_58 (Conv1D)              (None, 10, 32)       10240       conv1d_55[0][0]                  
__________________________________________________________________________________________________
conv1d_59 (Conv1D)              (None, 10, 32)       4096        max_pooling1d_8[0][0]            
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 10, 128)      0           conv1d_56[0][0]                  
                                                                 conv1d_57[0][0]                  
                                                                 conv1d_58[0][0]                  
                                                                 conv1d_59[0][0]                  
__________________________________________________________________________________________________
conv1d_60 (Conv1D)              (None, 10, 128)      4864        input_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 10, 128)      512         concatenate_8[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 10, 128)      512         conv1d_60[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 10, 128)      0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 10, 128)      0           batch_normalization_23[0][0]     
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 10, 128)      0           add_5[0][0]                      
__________________________________________________________________________________________________
conv1d_61 (Conv1D)              (None, 10, 32)       4096        activation_20[0][0]              
__________________________________________________________________________________________________
max_pooling1d_9 (MaxPooling1D)  (None, 10, 128)      0           activation_20[0][0]              
__________________________________________________________________________________________________
conv1d_62 (Conv1D)              (None, 10, 32)       40960       conv1d_61[0][0]                  
__________________________________________________________________________________________________
conv1d_63 (Conv1D)              (None, 10, 32)       20480       conv1d_61[0][0]                  
__________________________________________________________________________________________________
conv1d_64 (Conv1D)              (None, 10, 32)       10240       conv1d_61[0][0]                  
__________________________________________________________________________________________________
conv1d_65 (Conv1D)              (None, 10, 32)       4096        max_pooling1d_9[0][0]            
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 10, 128)      0           conv1d_62[0][0]                  
                                                                 conv1d_63[0][0]                  
                                                                 conv1d_64[0][0]                  
                                                                 conv1d_65[0][0]                  
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 10, 128)      512         concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 10, 128)      0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv1d_66 (Conv1D)              (None, 10, 32)       4096        activation_21[0][0]              
__________________________________________________________________________________________________
max_pooling1d_10 (MaxPooling1D) (None, 10, 128)      0           activation_21[0][0]              
__________________________________________________________________________________________________
conv1d_67 (Conv1D)              (None, 10, 32)       40960       conv1d_66[0][0]                  
__________________________________________________________________________________________________
conv1d_68 (Conv1D)              (None, 10, 32)       20480       conv1d_66[0][0]                  
__________________________________________________________________________________________________
conv1d_69 (Conv1D)              (None, 10, 32)       10240       conv1d_66[0][0]                  
__________________________________________________________________________________________________
conv1d_70 (Conv1D)              (None, 10, 32)       4096        max_pooling1d_10[0][0]           
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 10, 128)      0           conv1d_67[0][0]                  
                                                                 conv1d_68[0][0]                  
                                                                 conv1d_69[0][0]                  
                                                                 conv1d_70[0][0]                  
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 10, 128)      512         concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 10, 128)      0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
conv1d_71 (Conv1D)              (None, 10, 32)       4096        activation_22[0][0]              
__________________________________________________________________________________________________
max_pooling1d_11 (MaxPooling1D) (None, 10, 128)      0           activation_22[0][0]              
__________________________________________________________________________________________________
conv1d_72 (Conv1D)              (None, 10, 32)       40960       conv1d_71[0][0]                  
__________________________________________________________________________________________________
conv1d_73 (Conv1D)              (None, 10, 32)       20480       conv1d_71[0][0]                  
__________________________________________________________________________________________________
conv1d_74 (Conv1D)              (None, 10, 32)       10240       conv1d_71[0][0]                  
__________________________________________________________________________________________________
conv1d_75 (Conv1D)              (None, 10, 32)       4096        max_pooling1d_11[0][0]           
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 10, 128)      0           conv1d_72[0][0]                  
                                                                 conv1d_73[0][0]                  
                                                                 conv1d_74[0][0]                  
                                                                 conv1d_75[0][0]                  
__________________________________________________________________________________________________
conv1d_76 (Conv1D)              (None, 10, 128)      16384       activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 10, 128)      512         concatenate_11[0][0]             
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 10, 128)      512         conv1d_76[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 10, 128)      0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 10, 128)      0           batch_normalization_27[0][0]     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 10, 128)      0           add_6[0][0]                      
__________________________________________________________________________________________________
global_average_pooling1d_2 (Glo (None, 128)          0           activation_24[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 4)            516         global_average_pooling1d_2[0][0] 
==================================================================================================
Total params: 499,332
Trainable params: 497,284
Non-trainable params: 2,048
__________________________________________________________________________________________________
None
2022-06-17 14:09:52.353015: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2022-06-17 14:09:52.353503: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
Epoch 1/100
   1/1667 [..............................] - ETA: 0s - loss: 3.2478 - accuracy: 0.0000e+002022-06-17 14:09:56.060165: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2022-06-17 14:09:56.060338: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2022-06-17 14:09:56.350657: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 0 callback api events and 0 activity events. 
2022-06-17 14:09:56.358173: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/inception\train\plugins\profile\2022_06_17_12_09_56
2022-06-17 14:09:56.359768: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to C:\Users\apresekal\code\dl-4-tsc\out\logs/inception\train\plugins\profile\2022_06_17_12_09_56\TUD278848.trace.json.gz
2022-06-17 14:09:56.391350: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/inception\train\plugins\profile\2022_06_17_12_09_56
   2/1667 [..............................] - ETA: 4:42 - loss: 2.6328 - accuracy: 0.0469  2022-06-17 14:09:56.397555: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to C:\Users\apresekal\code\dl-4-tsc\out\logs/inception\train\plugins\profile\2022_06_17_12_09_56\TUD278848.memory_profile.json.gz
2022-06-17 14:09:56.403950: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/inception\train\plugins\profile\2022_06_17_12_09_56Dumped tool data for xplane.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/inception\train\plugins\profile\2022_06_17_12_09_56\TUD278848.xplane.pb
Dumped tool data for overview_page.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/inception\train\plugins\profile\2022_06_17_12_09_56\TUD278848.overview_page.pb
Dumped tool data for input_pipeline.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/inception\train\plugins\profile\2022_06_17_12_09_56\TUD278848.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/inception\train\plugins\profile\2022_06_17_12_09_56\TUD278848.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/inception\train\plugins\profile\2022_06_17_12_09_56\TUD278848.kernel_stats.pb

WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0245s vs `on_train_batch_end` time: 0.3145s). Check your callbacks.
1667/1667 [==============================] - 39s 24ms/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 4.4678 - val_accuracy: 0.8070
Epoch 2/100
1667/1667 [==============================] - 43s 26ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 12.2547 - val_accuracy: 0.2849
Epoch 3/100
1667/1667 [==============================] - 41s 24ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 8.6618 - val_accuracy: 0.7494
Epoch 4/100
1667/1667 [==============================] - 42s 25ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 9.7966 - val_accuracy: 0.7616
Epoch 5/100
1667/1667 [==============================] - 42s 25ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 12.1342 - val_accuracy: 0.7031
Epoch 6/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 9.3571 - val_accuracy: 0.7025
Epoch 7/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 7.4391 - val_accuracy: 0.8089
Epoch 8/100
1667/1667 [==============================] - 41s 24ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 11.9142 - val_accuracy: 0.7534
Epoch 9/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 14.8583 - val_accuracy: 0.7872
Epoch 10/100
1667/1667 [==============================] - 42s 25ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 13.2363 - val_accuracy: 0.7827
Epoch 11/100
1667/1667 [==============================] - 41s 24ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 45.7252 - val_accuracy: 0.7396
Epoch 12/100
1667/1667 [==============================] - 42s 25ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 106.1691 - val_accuracy: 0.7305
Epoch 13/100
1667/1667 [==============================] - 41s 24ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 31.6369 - val_accuracy: 0.7577
Epoch 14/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 31.7644 - val_accuracy: 0.8118
Epoch 15/100
1667/1667 [==============================] - 42s 25ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 44.6644 - val_accuracy: 0.7882
Epoch 16/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 89.4532 - val_accuracy: 0.7448
Epoch 17/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.3213e-04 - accuracy: 0.9999 - val_loss: 96.8608 - val_accuracy: 0.7427
Epoch 18/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.7811e-04 - accuracy: 0.9999 - val_loss: 37.0762 - val_accuracy: 0.8341
Epoch 19/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.8477e-04 - accuracy: 0.9999 - val_loss: 54.3174 - val_accuracy: 0.8225
Epoch 20/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 16.3882 - val_accuracy: 0.8403
Epoch 21/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.9498e-04 - accuracy: 0.9999 - val_loss: 59.7055 - val_accuracy: 0.7656
Epoch 22/100
1667/1667 [==============================] - 42s 25ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 30.9192 - val_accuracy: 0.8208
Epoch 23/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.6149e-04 - accuracy: 0.9999 - val_loss: 29.0467 - val_accuracy: 0.8246
Epoch 24/100
1667/1667 [==============================] - 43s 26ms/step - loss: 8.0686e-04 - accuracy: 0.9999 - val_loss: 34.0292 - val_accuracy: 0.7933
Epoch 25/100
1667/1667 [==============================] - 43s 26ms/step - loss: 9.7417e-04 - accuracy: 0.9999 - val_loss: 31.5208 - val_accuracy: 0.7875
Epoch 26/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.0900e-04 - accuracy: 0.9999 - val_loss: 31.3727 - val_accuracy: 0.8230
Epoch 27/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 25.9103 - val_accuracy: 0.7520
Epoch 28/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 48.0372 - val_accuracy: 0.8174
Epoch 29/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.8735e-04 - accuracy: 0.9998 - val_loss: 62.1253 - val_accuracy: 0.7625
Epoch 30/100
1667/1667 [==============================] - 39s 24ms/step - loss: 8.7913e-04 - accuracy: 0.9998 - val_loss: 30.4868 - val_accuracy: 0.8100
Epoch 31/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 15.4192 - val_accuracy: 0.8518
Epoch 32/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.5203e-04 - accuracy: 0.9999 - val_loss: 43.6020 - val_accuracy: 0.7078
Epoch 33/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.2776e-04 - accuracy: 0.9999 - val_loss: 46.1161 - val_accuracy: 0.7836
Epoch 34/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.9118e-04 - accuracy: 0.9999 - val_loss: 28.2196 - val_accuracy: 0.8018
Epoch 35/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.5144e-04 - accuracy: 0.9999 - val_loss: 14.2876 - val_accuracy: 0.8401
Epoch 36/100
1667/1667 [==============================] - 41s 24ms/step - loss: 8.6330e-04 - accuracy: 0.9999 - val_loss: 33.8185 - val_accuracy: 0.8039
Epoch 37/100
1667/1667 [==============================] - 39s 24ms/step - loss: 9.1570e-04 - accuracy: 0.9999 - val_loss: 23.7939 - val_accuracy: 0.8452
Epoch 38/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.5396e-04 - accuracy: 0.9999 - val_loss: 17.0143 - val_accuracy: 0.8863
Epoch 39/100
1667/1667 [==============================] - 41s 24ms/step - loss: 8.8721e-04 - accuracy: 0.9999 - val_loss: 30.8328 - val_accuracy: 0.8295
Epoch 40/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.4582e-04 - accuracy: 0.9999 - val_loss: 40.9289 - val_accuracy: 0.8112
Epoch 41/100
1667/1667 [==============================] - 41s 24ms/step - loss: 8.9687e-04 - accuracy: 0.9998 - val_loss: 30.8975 - val_accuracy: 0.8147
Epoch 42/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 125.4693 - val_accuracy: 0.5275
Epoch 43/100
1667/1667 [==============================] - 42s 25ms/step - loss: 8.5725e-04 - accuracy: 0.9999 - val_loss: 47.3799 - val_accuracy: 0.5302
Epoch 44/100
1667/1667 [==============================] - 41s 24ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 60.7998 - val_accuracy: 0.5398
Epoch 45/100
1667/1667 [==============================] - 38s 23ms/step - loss: 8.8526e-04 - accuracy: 0.9999 - val_loss: 17.7813 - val_accuracy: 0.8582
Epoch 46/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.0557e-04 - accuracy: 0.9999 - val_loss: 397.3450 - val_accuracy: 0.5051
Epoch 47/100
1667/1667 [==============================] - 41s 24ms/step - loss: 9.3734e-04 - accuracy: 0.9999 - val_loss: 19.8606 - val_accuracy: 0.8419
Epoch 48/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.3976e-04 - accuracy: 0.9999 - val_loss: 24.4581 - val_accuracy: 0.8780
Epoch 49/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.0347e-04 - accuracy: 0.9999 - val_loss: 84.8440 - val_accuracy: 0.5747
Epoch 50/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.8352e-04 - accuracy: 0.9998 - val_loss: 74.2229 - val_accuracy: 0.8106
Epoch 51/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 39.8690 - val_accuracy: 0.7928
Epoch 52/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.4956e-04 - accuracy: 0.9999 - val_loss: 36.6414 - val_accuracy: 0.8127
Epoch 53/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.7814e-04 - accuracy: 0.9999 - val_loss: 32.3010 - val_accuracy: 0.8179
Epoch 54/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.4690e-04 - accuracy: 0.9999 - val_loss: 61.9928 - val_accuracy: 0.5516
Epoch 55/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.7186e-04 - accuracy: 0.9999 - val_loss: 218.5659 - val_accuracy: 0.5544
Epoch 56/100
1667/1667 [==============================] - 34s 20ms/step - loss: 9.2056e-04 - accuracy: 0.9999 - val_loss: 229.3945 - val_accuracy: 0.5583
Epoch 57/100
1667/1667 [==============================] - 37s 22ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 370.4334 - val_accuracy: 0.5278
Epoch 58/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.7987e-04 - accuracy: 0.9999 - val_loss: 310.1892 - val_accuracy: 0.5381
Epoch 59/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.0423e-04 - accuracy: 0.9999 - val_loss: 185.4615 - val_accuracy: 0.5582
Epoch 60/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.3861e-04 - accuracy: 0.9999 - val_loss: 75.8801 - val_accuracy: 0.5784
Epoch 61/100
1667/1667 [==============================] - 41s 24ms/step - loss: 9.0049e-04 - accuracy: 0.9998 - val_loss: 26.5511 - val_accuracy: 0.8374
Epoch 62/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.7297e-04 - accuracy: 0.9999 - val_loss: 63.3609 - val_accuracy: 0.7829
Epoch 63/100
1667/1667 [==============================] - 36s 22ms/step - loss: 9.4826e-04 - accuracy: 0.9999 - val_loss: 52.2427 - val_accuracy: 0.7938
Epoch 64/100
1667/1667 [==============================] - 39s 23ms/step - loss: 9.1513e-04 - accuracy: 0.9999 - val_loss: 115.3528 - val_accuracy: 0.5018
Epoch 65/100
1667/1667 [==============================] - 35s 21ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 72.5802 - val_accuracy: 0.7436
Epoch 66/100
1667/1667 [==============================] - 23s 14ms/step - loss: 9.7085e-04 - accuracy: 0.9999 - val_loss: 64.7457 - val_accuracy: 0.7540
Epoch 67/100
1667/1667 [==============================] - 21s 13ms/step - loss: 8.3850e-04 - accuracy: 0.9999 - val_loss: 61.5391 - val_accuracy: 0.7602
Epoch 68/100
1667/1667 [==============================] - 30s 18ms/step - loss: 8.5493e-04 - accuracy: 0.9999 - val_loss: 60.9981 - val_accuracy: 0.7970
Epoch 69/100
1667/1667 [==============================] - 35s 21ms/step - loss: 8.7761e-04 - accuracy: 0.9999 - val_loss: 56.5551 - val_accuracy: 0.7980
Epoch 70/100
1667/1667 [==============================] - 38s 23ms/step - loss: 9.2058e-04 - accuracy: 0.9999 - val_loss: 46.9362 - val_accuracy: 0.8307
Epoch 71/100
1667/1667 [==============================] - 39s 23ms/step - loss: 8.8861e-04 - accuracy: 0.9999 - val_loss: 33.8285 - val_accuracy: 0.8455
Epoch 72/100
1667/1667 [==============================] - 41s 24ms/step - loss: 9.7963e-04 - accuracy: 0.9999 - val_loss: 25.3494 - val_accuracy: 0.8509
Epoch 73/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0137 - accuracy: 0.9998 - val_loss: 59.1150 - val_accuracy: 0.8082
Epoch 74/100
1667/1667 [==============================] - 39s 24ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 25.2585 - val_accuracy: 0.8838
Epoch 75/100
1667/1667 [==============================] - 41s 25ms/step - loss: 7.9508e-04 - accuracy: 0.9999 - val_loss: 24.0138 - val_accuracy: 0.8841
Epoch 76/100
1667/1667 [==============================] - 38s 23ms/step - loss: 8.5549e-04 - accuracy: 0.9999 - val_loss: 27.4079 - val_accuracy: 0.8738
Epoch 77/100
1667/1667 [==============================] - 40s 24ms/step - loss: 7.8025e-04 - accuracy: 0.9999 - val_loss: 38.0482 - val_accuracy: 0.8516
Epoch 78/100
1667/1667 [==============================] - 39s 23ms/step - loss: 9.9084e-04 - accuracy: 0.9999 - val_loss: 172.3542 - val_accuracy: 0.7674
Epoch 79/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.8337e-04 - accuracy: 0.9999 - val_loss: 101.2924 - val_accuracy: 0.6366
Epoch 80/100
1667/1667 [==============================] - 41s 24ms/step - loss: 9.0649e-04 - accuracy: 0.9999 - val_loss: 103.3133 - val_accuracy: 0.5220
Epoch 81/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 20.5686 - val_accuracy: 0.8636
Epoch 82/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.9430e-04 - accuracy: 0.9999 - val_loss: 27.5539 - val_accuracy: 0.6106
Epoch 83/100
1667/1667 [==============================] - 41s 24ms/step - loss: 9.1437e-04 - accuracy: 0.9999 - val_loss: 174.8060 - val_accuracy: 0.5887
Epoch 84/100
1667/1667 [==============================] - 41s 24ms/step - loss: 8.5178e-04 - accuracy: 0.9999 - val_loss: 438.1819 - val_accuracy: 0.4793
Epoch 85/100
1667/1667 [==============================] - 41s 24ms/step - loss: 9.0427e-04 - accuracy: 0.9999 - val_loss: 59.4956 - val_accuracy: 0.8204
Epoch 86/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.6163e-04 - accuracy: 0.9999 - val_loss: 43.3348 - val_accuracy: 0.8519
Epoch 87/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.0159e-04 - accuracy: 0.9999 - val_loss: 126.8288 - val_accuracy: 0.5243
Epoch 88/100
1667/1667 [==============================] - 38s 23ms/step - loss: 8.8161e-04 - accuracy: 0.9999 - val_loss: 62.5067 - val_accuracy: 0.5709
Epoch 89/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 17.0359 - val_accuracy: 0.8879
Epoch 90/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.8866e-04 - accuracy: 0.9999 - val_loss: 31.9008 - val_accuracy: 0.8646
Epoch 91/100
1667/1667 [==============================] - 38s 23ms/step - loss: 8.7847e-04 - accuracy: 0.9999 - val_loss: 35.8780 - val_accuracy: 0.8614
Epoch 92/100
1667/1667 [==============================] - 39s 24ms/step - loss: 9.0426e-04 - accuracy: 0.9999 - val_loss: 38.3080 - val_accuracy: 0.8701
Epoch 93/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.0124e-04 - accuracy: 0.9999 - val_loss: 52.6516 - val_accuracy: 0.8400
Epoch 94/100
1667/1667 [==============================] - 41s 24ms/step - loss: 8.7599e-04 - accuracy: 0.9999 - val_loss: 41.4217 - val_accuracy: 0.8616
Epoch 95/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.8765e-04 - accuracy: 0.9999 - val_loss: 360.9905 - val_accuracy: 0.5248
Epoch 96/100
1667/1667 [==============================] - 39s 24ms/step - loss: 8.3979e-04 - accuracy: 0.9999 - val_loss: 380.7219 - val_accuracy: 0.5285
Epoch 97/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 25.9032 - val_accuracy: 0.8952
Epoch 98/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.5293e-04 - accuracy: 0.9999 - val_loss: 29.3184 - val_accuracy: 0.8882
Epoch 99/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.9296e-04 - accuracy: 0.9999 - val_loss: 41.7637 - val_accuracy: 0.8781
Epoch 100/100
1667/1667 [==============================] - 39s 23ms/step - loss: 9.3937e-04 - accuracy: 0.9999 - val_loss: 26.9507 - val_accuracy: 0.8955
Model: "functional_11"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_6 (InputLayer)            [(None, 10, 38)]     0                                            
__________________________________________________________________________________________________
conv1d_109 (Conv1D)             (None, 10, 32)       1216        input_6[0][0]                    
__________________________________________________________________________________________________
max_pooling1d_18 (MaxPooling1D) (None, 10, 38)       0           input_6[0][0]                    
__________________________________________________________________________________________________
conv1d_110 (Conv1D)             (None, 10, 32)       40960       conv1d_109[0][0]                 
__________________________________________________________________________________________________
conv1d_111 (Conv1D)             (None, 10, 32)       20480       conv1d_109[0][0]                 
__________________________________________________________________________________________________
conv1d_112 (Conv1D)             (None, 10, 32)       10240       conv1d_109[0][0]                 
__________________________________________________________________________________________________
conv1d_113 (Conv1D)             (None, 10, 32)       1216        max_pooling1d_18[0][0]           
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 10, 128)      0           conv1d_110[0][0]                 
                                                                 conv1d_111[0][0]                 
                                                                 conv1d_112[0][0]                 
                                                                 conv1d_113[0][0]                 
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 10, 128)      512         concatenate_18[0][0]             
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 10, 128)      0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv1d_114 (Conv1D)             (None, 10, 32)       4096        activation_33[0][0]              
__________________________________________________________________________________________________
max_pooling1d_19 (MaxPooling1D) (None, 10, 128)      0           activation_33[0][0]              
__________________________________________________________________________________________________
conv1d_115 (Conv1D)             (None, 10, 32)       40960       conv1d_114[0][0]                 
__________________________________________________________________________________________________
conv1d_116 (Conv1D)             (None, 10, 32)       20480       conv1d_114[0][0]                 
__________________________________________________________________________________________________
conv1d_117 (Conv1D)             (None, 10, 32)       10240       conv1d_114[0][0]                 
__________________________________________________________________________________________________
conv1d_118 (Conv1D)             (None, 10, 32)       4096        max_pooling1d_19[0][0]           
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 10, 128)      0           conv1d_115[0][0]                 
                                                                 conv1d_116[0][0]                 
                                                                 conv1d_117[0][0]                 
                                                                 conv1d_118[0][0]                 
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 10, 128)      512         concatenate_19[0][0]             
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 10, 128)      0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
conv1d_119 (Conv1D)             (None, 10, 32)       4096        activation_34[0][0]              
__________________________________________________________________________________________________
max_pooling1d_20 (MaxPooling1D) (None, 10, 128)      0           activation_34[0][0]              
__________________________________________________________________________________________________
conv1d_120 (Conv1D)             (None, 10, 32)       40960       conv1d_119[0][0]                 
__________________________________________________________________________________________________
conv1d_121 (Conv1D)             (None, 10, 32)       20480       conv1d_119[0][0]                 
__________________________________________________________________________________________________
conv1d_122 (Conv1D)             (None, 10, 32)       10240       conv1d_119[0][0]                 
__________________________________________________________________________________________________
conv1d_123 (Conv1D)             (None, 10, 32)       4096        max_pooling1d_20[0][0]           
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 10, 128)      0           conv1d_120[0][0]                 
                                                                 conv1d_121[0][0]                 
                                                                 conv1d_122[0][0]                 
                                                                 conv1d_123[0][0]                 
__________________________________________________________________________________________________
conv1d_124 (Conv1D)             (None, 10, 128)      4864        input_6[0][0]                    
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 10, 128)      512         concatenate_20[0][0]             
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 10, 128)      512         conv1d_124[0][0]                 
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 10, 128)      0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 10, 128)      0           batch_normalization_39[0][0]     
                                                                 activation_35[0][0]              
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 10, 128)      0           add_9[0][0]                      
__________________________________________________________________________________________________
conv1d_125 (Conv1D)             (None, 10, 32)       4096        activation_36[0][0]              
__________________________________________________________________________________________________
max_pooling1d_21 (MaxPooling1D) (None, 10, 128)      0           activation_36[0][0]              
__________________________________________________________________________________________________
conv1d_126 (Conv1D)             (None, 10, 32)       40960       conv1d_125[0][0]                 
__________________________________________________________________________________________________
conv1d_127 (Conv1D)             (None, 10, 32)       20480       conv1d_125[0][0]                 
__________________________________________________________________________________________________
conv1d_128 (Conv1D)             (None, 10, 32)       10240       conv1d_125[0][0]                 
__________________________________________________________________________________________________
conv1d_129 (Conv1D)             (None, 10, 32)       4096        max_pooling1d_21[0][0]           
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 10, 128)      0           conv1d_126[0][0]                 
                                                                 conv1d_127[0][0]                 
                                                                 conv1d_128[0][0]                 
                                                                 conv1d_129[0][0]                 
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 10, 128)      512         concatenate_21[0][0]             
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 10, 128)      0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv1d_130 (Conv1D)             (None, 10, 32)       4096        activation_37[0][0]              
__________________________________________________________________________________________________
max_pooling1d_22 (MaxPooling1D) (None, 10, 128)      0           activation_37[0][0]              
__________________________________________________________________________________________________
conv1d_131 (Conv1D)             (None, 10, 32)       40960       conv1d_130[0][0]                 
__________________________________________________________________________________________________
conv1d_132 (Conv1D)             (None, 10, 32)       20480       conv1d_130[0][0]                 
__________________________________________________________________________________________________
conv1d_133 (Conv1D)             (None, 10, 32)       10240       conv1d_130[0][0]                 
__________________________________________________________________________________________________
conv1d_134 (Conv1D)             (None, 10, 32)       4096        max_pooling1d_22[0][0]           
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 10, 128)      0           conv1d_131[0][0]                 
                                                                 conv1d_132[0][0]                 
                                                                 conv1d_133[0][0]                 
                                                                 conv1d_134[0][0]                 
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 10, 128)      512         concatenate_22[0][0]             
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 10, 128)      0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
conv1d_135 (Conv1D)             (None, 10, 32)       4096        activation_38[0][0]              
__________________________________________________________________________________________________
max_pooling1d_23 (MaxPooling1D) (None, 10, 128)      0           activation_38[0][0]              
__________________________________________________________________________________________________
conv1d_136 (Conv1D)             (None, 10, 32)       40960       conv1d_135[0][0]                 
__________________________________________________________________________________________________
conv1d_137 (Conv1D)             (None, 10, 32)       20480       conv1d_135[0][0]                 
__________________________________________________________________________________________________
conv1d_138 (Conv1D)             (None, 10, 32)       10240       conv1d_135[0][0]                 
__________________________________________________________________________________________________
conv1d_139 (Conv1D)             (None, 10, 32)       4096        max_pooling1d_23[0][0]           
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 10, 128)      0           conv1d_136[0][0]                 
                                                                 conv1d_137[0][0]                 
                                                                 conv1d_138[0][0]                 
                                                                 conv1d_139[0][0]                 
__________________________________________________________________________________________________
conv1d_140 (Conv1D)             (None, 10, 128)      16384       activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 10, 128)      512         concatenate_23[0][0]             
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 10, 128)      512         conv1d_140[0][0]                 
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 10, 128)      0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 10, 128)      0           batch_normalization_43[0][0]     
                                                                 activation_39[0][0]              
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 10, 128)      0           add_10[0][0]                     
__________________________________________________________________________________________________
global_average_pooling1d_4 (Glo (None, 128)          0           activation_40[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 4)            516         global_average_pooling1d_4[0][0] 
==================================================================================================
Total params: 499,332
Trainable params: 497,284
Non-trainable params: 2,048
__________________________________________________________________________________________________
None
2022-06-17 15:16:27.347557: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2022-06-17 15:16:27.348013: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
Epoch 1/100
   1/1667 [..............................] - ETA: 0s - loss: 3.8331 - accuracy: 0.0000e+002022-06-17 15:16:30.377269: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2022-06-17 15:16:30.377430: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2022-06-17 15:16:30.674546: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 0 callback api events and 0 activity events. 
2022-06-17 15:16:30.687222: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/fcn\train\plugins\profile\2022_06_17_13_16_30
2022-06-17 15:16:30.689916: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to C:\Users\apresekal\code\dl-4-tsc\out\logs/fcn\train\plugins\profile\2022_06_17_13_16_30\TUD278848.trace.json.gz
2022-06-17 15:16:30.746747: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/fcn\train\plugins\profile\2022_06_17_13_16_30
2022-06-17 15:16:30.753221: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to C:\Users\apresekal\code\dl-4-tsc\out\logs/fcn\train\plugins\profile\2022_06_17_13_16_30\TUD278848.memory_profile.json.gz
2022-06-17 15:16:30.763742: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/fcn\train\plugins\profile\2022_06_17_13_16_30Dumped tool data for xplane.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/fcn\train\plugins\profile\2022_06_17_13_16_30\TUD278848.xplane.pb
Dumped tool data for overview_page.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/fcn\train\plugins\profile\2022_06_17_13_16_30\TUD278848.overview_page.pb
Dumped tool data for input_pipeline.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/fcn\train\plugins\profile\2022_06_17_13_16_30\TUD278848.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/fcn\train\plugins\profile\2022_06_17_13_16_30\TUD278848.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/fcn\train\plugins\profile\2022_06_17_13_16_30\TUD278848.kernel_stats.pb

WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0309s vs `on_train_batch_end` time: 0.3657s). Check your callbacks.
1667/1667 [==============================] - 39s 23ms/step - loss: 0.0164 - accuracy: 0.9962 - val_loss: 4.8525 - val_accuracy: 0.5653
Epoch 2/100
1667/1667 [==============================] - 41s 24ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 4.7754 - val_accuracy: 0.5738
Epoch 3/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 13.8685 - val_accuracy: 0.7734
Epoch 4/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 17.9567 - val_accuracy: 0.2814
Epoch 5/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 14.3553 - val_accuracy: 0.6840
Epoch 6/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 20.8025 - val_accuracy: 0.7575
Epoch 7/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 12.3391 - val_accuracy: 0.8062
Epoch 8/100
1667/1667 [==============================] - 39s 23ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 21.6277 - val_accuracy: 0.7186
Epoch 9/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 29.6504 - val_accuracy: 0.7484
Epoch 10/100
1667/1667 [==============================] - 41s 24ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 74.1543 - val_accuracy: 0.7574
Epoch 11/100
1667/1667 [==============================] - 43s 26ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 10.4193 - val_accuracy: 0.8208
Epoch 12/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.2829e-04 - accuracy: 0.9999 - val_loss: 15.3045 - val_accuracy: 0.7781
Epoch 13/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 9.6277 - val_accuracy: 0.7979
Epoch 14/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 8.3476 - val_accuracy: 0.8243
Epoch 15/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.6054e-04 - accuracy: 0.9998 - val_loss: 12.8123 - val_accuracy: 0.8029
Epoch 16/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 7.4312 - val_accuracy: 0.7929
Epoch 17/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.9272e-04 - accuracy: 0.9998 - val_loss: 44.6952 - val_accuracy: 0.7315
Epoch 18/100
1667/1667 [==============================] - 41s 24ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 16.5609 - val_accuracy: 0.6679
Epoch 19/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 21.8251 - val_accuracy: 0.7642
Epoch 20/100
1667/1667 [==============================] - 41s 24ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 85.4319 - val_accuracy: 0.7456
Epoch 21/100
1667/1667 [==============================] - 37s 22ms/step - loss: 9.3139e-04 - accuracy: 0.9999 - val_loss: 222.4993 - val_accuracy: 0.7353
Epoch 22/100
1667/1667 [==============================] - 41s 24ms/step - loss: 9.2954e-04 - accuracy: 0.9999 - val_loss: 144.8408 - val_accuracy: 0.7496
Epoch 23/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.2436e-04 - accuracy: 0.9999 - val_loss: 86.2680 - val_accuracy: 0.7415
Epoch 24/100
1667/1667 [==============================] - 41s 24ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 118.7155 - val_accuracy: 0.7355
Epoch 25/100
1667/1667 [==============================] - 43s 26ms/step - loss: 9.2448e-04 - accuracy: 0.9999 - val_loss: 153.2261 - val_accuracy: 0.7384
Epoch 26/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.6185e-04 - accuracy: 0.9999 - val_loss: 130.3818 - val_accuracy: 0.7400
Epoch 27/100
1667/1667 [==============================] - 42s 25ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 18.1466 - val_accuracy: 0.7941
Epoch 28/100
1667/1667 [==============================] - 43s 26ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 71.1091 - val_accuracy: 0.7468
Epoch 29/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.4350e-04 - accuracy: 0.9999 - val_loss: 82.7361 - val_accuracy: 0.4877
Epoch 30/100
1667/1667 [==============================] - 43s 26ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 115.8503 - val_accuracy: 0.4870
Epoch 31/100
1667/1667 [==============================] - 43s 26ms/step - loss: 9.1155e-04 - accuracy: 0.9999 - val_loss: 54.9952 - val_accuracy: 0.5098
Epoch 32/100
1667/1667 [==============================] - 42s 25ms/step - loss: 8.6348e-04 - accuracy: 0.9999 - val_loss: 416.7629 - val_accuracy: 0.4855
Epoch 33/100
1667/1667 [==============================] - 42s 25ms/step - loss: 8.3435e-04 - accuracy: 0.9999 - val_loss: 52.4320 - val_accuracy: 0.5514
Epoch 34/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 26.3406 - val_accuracy: 0.8046
Epoch 35/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.7096e-04 - accuracy: 0.9999 - val_loss: 42.7975 - val_accuracy: 0.6896
Epoch 36/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.9360e-04 - accuracy: 0.9998 - val_loss: 45.1948 - val_accuracy: 0.5536
Epoch 37/100
1667/1667 [==============================] - 42s 25ms/step - loss: 8.4599e-04 - accuracy: 0.9999 - val_loss: 97.4372 - val_accuracy: 0.5534
Epoch 38/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.7100e-04 - accuracy: 0.9999 - val_loss: 129.7482 - val_accuracy: 0.5724
Epoch 39/100
1667/1667 [==============================] - 39s 23ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 209.3710 - val_accuracy: 0.4909
Epoch 40/100
1667/1667 [==============================] - 43s 26ms/step - loss: 9.1214e-04 - accuracy: 0.9998 - val_loss: 33.1838 - val_accuracy: 0.6937
Epoch 41/100
1667/1667 [==============================] - 41s 24ms/step - loss: 8.4958e-04 - accuracy: 0.9999 - val_loss: 16.1202 - val_accuracy: 0.8238
Epoch 42/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.2273e-04 - accuracy: 0.9999 - val_loss: 21.2834 - val_accuracy: 0.8106
Epoch 43/100
1667/1667 [==============================] - 42s 25ms/step - loss: 8.8802e-04 - accuracy: 0.9999 - val_loss: 58.9700 - val_accuracy: 0.7660
Epoch 44/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.1353e-04 - accuracy: 0.9999 - val_loss: 98.0232 - val_accuracy: 0.7410
Epoch 45/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.3114e-04 - accuracy: 0.9999 - val_loss: 109.1953 - val_accuracy: 0.5088
Epoch 46/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.8761e-04 - accuracy: 0.9998 - val_loss: 165.7595 - val_accuracy: 0.5271
Epoch 47/100
1667/1667 [==============================] - 41s 24ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 251.6087 - val_accuracy: 0.5187
Epoch 48/100
1667/1667 [==============================] - 42s 25ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 137.0530 - val_accuracy: 0.5456
Epoch 49/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.0791e-04 - accuracy: 0.9999 - val_loss: 132.0995 - val_accuracy: 0.5562
Epoch 50/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.3331e-04 - accuracy: 0.9999 - val_loss: 180.3270 - val_accuracy: 0.5605
Epoch 51/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.9588e-04 - accuracy: 0.9999 - val_loss: 169.0899 - val_accuracy: 0.5463
Epoch 52/100
1667/1667 [==============================] - 41s 24ms/step - loss: 8.9597e-04 - accuracy: 0.9999 - val_loss: 491.2796 - val_accuracy: 0.5313
Epoch 53/100
1667/1667 [==============================] - 38s 23ms/step - loss: 9.4282e-04 - accuracy: 0.9999 - val_loss: 340.7945 - val_accuracy: 0.5218
Epoch 54/100
1667/1667 [==============================] - 35s 21ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 443.1304 - val_accuracy: 0.5453
Epoch 55/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.9669e-04 - accuracy: 0.9999 - val_loss: 486.5877 - val_accuracy: 0.5383
Epoch 56/100
1667/1667 [==============================] - 38s 23ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 257.1100 - val_accuracy: 0.4916
Epoch 57/100
1667/1667 [==============================] - 39s 23ms/step - loss: 9.3021e-04 - accuracy: 0.9999 - val_loss: 431.4363 - val_accuracy: 0.5059
Epoch 58/100
1667/1667 [==============================] - 41s 24ms/step - loss: 8.6191e-04 - accuracy: 0.9999 - val_loss: 461.8262 - val_accuracy: 0.4871
Epoch 59/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.1186e-04 - accuracy: 0.9999 - val_loss: 774.8183 - val_accuracy: 0.5278
Epoch 60/100
1667/1667 [==============================] - 39s 23ms/step - loss: 9.8417e-04 - accuracy: 0.9998 - val_loss: 652.7532 - val_accuracy: 0.5643
Epoch 61/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.5073e-04 - accuracy: 0.9999 - val_loss: 1001.8408 - val_accuracy: 0.5466
Epoch 62/100
1667/1667 [==============================] - 41s 24ms/step - loss: 9.4723e-04 - accuracy: 0.9999 - val_loss: 951.9133 - val_accuracy: 0.5546
Epoch 63/100
1667/1667 [==============================] - 42s 25ms/step - loss: 8.8331e-04 - accuracy: 0.9999 - val_loss: 1437.3628 - val_accuracy: 0.5334
Epoch 64/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.7375e-04 - accuracy: 0.9999 - val_loss: 820.7458 - val_accuracy: 0.5603
Epoch 65/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 541.1843 - val_accuracy: 0.5282
Epoch 66/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.3730e-04 - accuracy: 0.9999 - val_loss: 865.1345 - val_accuracy: 0.4634
Epoch 67/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.1067e-04 - accuracy: 0.9999 - val_loss: 1052.5142 - val_accuracy: 0.4840
Epoch 68/100
1667/1667 [==============================] - 41s 24ms/step - loss: 9.4762e-04 - accuracy: 0.9999 - val_loss: 828.5017 - val_accuracy: 0.4949
Epoch 69/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.7346e-04 - accuracy: 0.9998 - val_loss: 536.0249 - val_accuracy: 0.4951
Epoch 70/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.9361e-04 - accuracy: 0.9999 - val_loss: 878.1487 - val_accuracy: 0.4681
Epoch 71/100
1667/1667 [==============================] - 39s 24ms/step - loss: 9.0725e-04 - accuracy: 0.9999 - val_loss: 593.4801 - val_accuracy: 0.4025
Epoch 72/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 441.9002 - val_accuracy: 0.4974
Epoch 73/100
1667/1667 [==============================] - 42s 25ms/step - loss: 8.6221e-04 - accuracy: 0.9999 - val_loss: 664.8427 - val_accuracy: 0.4994
Epoch 74/100
1667/1667 [==============================] - 42s 25ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 94.8376 - val_accuracy: 0.4971
Epoch 75/100
1667/1667 [==============================] - 42s 25ms/step - loss: 8.5022e-04 - accuracy: 0.9999 - val_loss: 104.5971 - val_accuracy: 0.5113
Epoch 76/100
1667/1667 [==============================] - 40s 24ms/step - loss: 8.9180e-04 - accuracy: 0.9999 - val_loss: 104.8135 - val_accuracy: 0.5022
Epoch 77/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.6282e-04 - accuracy: 0.9999 - val_loss: 108.0474 - val_accuracy: 0.5208
Epoch 78/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.6274e-04 - accuracy: 0.9999 - val_loss: 234.3745 - val_accuracy: 0.5522
Epoch 79/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.1309e-04 - accuracy: 0.9999 - val_loss: 533.9226 - val_accuracy: 0.4707
Epoch 80/100
1667/1667 [==============================] - 42s 25ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 311.0858 - val_accuracy: 0.4738
Epoch 81/100
1667/1667 [==============================] - 42s 25ms/step - loss: 8.8891e-04 - accuracy: 0.9999 - val_loss: 556.6036 - val_accuracy: 0.4590
Epoch 82/100
1667/1667 [==============================] - 42s 25ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 985.5028 - val_accuracy: 0.4659
Epoch 83/100
1667/1667 [==============================] - 42s 25ms/step - loss: 8.7742e-04 - accuracy: 0.9999 - val_loss: 1042.1920 - val_accuracy: 0.4637
Epoch 84/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.8708e-04 - accuracy: 0.9999 - val_loss: 606.5163 - val_accuracy: 0.4893
Epoch 85/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.8979e-04 - accuracy: 0.9999 - val_loss: 948.6176 - val_accuracy: 0.4858
Epoch 86/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 982.8368 - val_accuracy: 0.4583
Epoch 87/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 670.9607 - val_accuracy: 0.5194
Epoch 88/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.7556e-04 - accuracy: 0.9999 - val_loss: 630.4376 - val_accuracy: 0.5058
Epoch 89/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.2722e-04 - accuracy: 0.9999 - val_loss: 802.4867 - val_accuracy: 0.5404
Epoch 90/100
1667/1667 [==============================] - 41s 24ms/step - loss: 9.3434e-04 - accuracy: 0.9999 - val_loss: 2512.2241 - val_accuracy: 0.4499
Epoch 91/100
1667/1667 [==============================] - 41s 25ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 414.8636 - val_accuracy: 0.5678
Epoch 92/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.7429e-04 - accuracy: 0.9999 - val_loss: 438.0763 - val_accuracy: 0.5668
Epoch 93/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.5897e-04 - accuracy: 0.9999 - val_loss: 452.8037 - val_accuracy: 0.5672
Epoch 94/100
1667/1667 [==============================] - 41s 25ms/step - loss: 8.8578e-04 - accuracy: 0.9999 - val_loss: 564.5908 - val_accuracy: 0.5656
Epoch 95/100
1667/1667 [==============================] - 40s 24ms/step - loss: 9.3304e-04 - accuracy: 0.9999 - val_loss: 580.0847 - val_accuracy: 0.5688
Epoch 96/100
1667/1667 [==============================] - 42s 25ms/step - loss: 9.2753e-04 - accuracy: 0.9999 - val_loss: 648.5220 - val_accuracy: 0.5799
Epoch 97/100
1667/1667 [==============================] - 25s 15ms/step - loss: 8.0495e-04 - accuracy: 0.9999 - val_loss: 745.7120 - val_accuracy: 0.5728
Epoch 98/100
1667/1667 [==============================] - 40s 24ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 808.3103 - val_accuracy: 0.5455
Epoch 99/100
1667/1667 [==============================] - 41s 25ms/step - loss: 9.8955e-04 - accuracy: 0.9998 - val_loss: 407.8485 - val_accuracy: 0.5838
Epoch 100/100
1667/1667 [==============================] - 42s 25ms/step - loss: 7.8206e-04 - accuracy: 0.9999 - val_loss: 734.3737 - val_accuracy: 0.5744
Model: "functional_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_8 (InputLayer)         [(None, 10, 38)]          0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 380)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 380)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 500)               190500    
_________________________________________________________________
dropout_5 (Dropout)          (None, 500)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 500)               250500    
_________________________________________________________________
dropout_6 (Dropout)          (None, 500)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 500)               250500    
_________________________________________________________________
dropout_7 (Dropout)          (None, 500)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 4)                 2004      
=================================================================
Total params: 693,504
Trainable params: 693,504
Non-trainable params: 0
_________________________________________________________________
None
2022-06-17 16:24:31.429600: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2022-06-17 16:24:31.429766: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
Epoch 1/100
   1/1667 [..............................] - ETA: 0s - loss: 1.3391 - accuracy: 0.37502022-06-17 16:24:32.059034: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.
2022-06-17 16:24:32.059196: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2022-06-17 16:24:32.144993: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 0 callback api events and 0 activity events. 
2022-06-17 16:24:32.148406: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/mlp\train\plugins\profile\2022_06_17_14_24_32
2022-06-17 16:24:32.149785: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to C:\Users\apresekal\code\dl-4-tsc\out\logs/mlp\train\plugins\profile\2022_06_17_14_24_32\TUD278848.trace.json.gz
2022-06-17 16:24:32.154345: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/mlp\train\plugins\profile\2022_06_17_14_24_32
2022-06-17 16:24:32.156260: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to C:\Users\apresekal\code\dl-4-tsc\out\logs/mlp\train\plugins\profile\2022_06_17_14_24_32\TUD278848.memory_profile.json.gz
   2/1667 [..............................] - ETA: 1:35 - loss: 1.3308 - accuracy: 0.43752022-06-17 16:24:32.166185: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: C:\Users\apresekal\code\dl-4-tsc\out\logs/mlp\train\plugins\profile\2022_06_17_14_24_32Dumped tool data for xplane.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/mlp\train\plugins\profile\2022_06_17_14_24_32\TUD278848.xplane.pb
Dumped tool data for overview_page.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/mlp\train\plugins\profile\2022_06_17_14_24_32\TUD278848.overview_page.pb
Dumped tool data for input_pipeline.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/mlp\train\plugins\profile\2022_06_17_14_24_32\TUD278848.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/mlp\train\plugins\profile\2022_06_17_14_24_32\TUD278848.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to C:\Users\apresekal\code\dl-4-tsc\out\logs/mlp\train\plugins\profile\2022_06_17_14_24_32\TUD278848.kernel_stats.pb

WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.1151s). Check your callbacks.
1667/1667 [==============================] - 5s 3ms/step - loss: 1.0968 - accuracy: 0.9501 - val_loss: 2.2006 - val_accuracy: 0.1903
Epoch 2/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.7964 - accuracy: 0.9789 - val_loss: 3.4919 - val_accuracy: 0.1903
Epoch 3/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.5770 - accuracy: 0.9789 - val_loss: 5.5996 - val_accuracy: 0.1903
Epoch 4/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.3663 - accuracy: 0.9789 - val_loss: 7.8828 - val_accuracy: 0.1903
Epoch 5/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.2473 - accuracy: 0.9789 - val_loss: 9.0900 - val_accuracy: 0.1903
Epoch 6/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.1948 - accuracy: 0.9789 - val_loss: 9.3082 - val_accuracy: 0.1903
Epoch 7/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.1685 - accuracy: 0.9789 - val_loss: 8.9360 - val_accuracy: 0.1903
Epoch 8/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.1503 - accuracy: 0.9789 - val_loss: 8.2715 - val_accuracy: 0.1903
Epoch 9/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.1358 - accuracy: 0.9789 - val_loss: 7.5107 - val_accuracy: 0.1903
Epoch 10/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.1226 - accuracy: 0.9789 - val_loss: 6.7342 - val_accuracy: 0.1903
Epoch 11/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.1114 - accuracy: 0.9789 - val_loss: 5.9994 - val_accuracy: 0.1903
Epoch 12/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.1006 - accuracy: 0.9789 - val_loss: 5.3273 - val_accuracy: 0.1903
Epoch 13/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0913 - accuracy: 0.9789 - val_loss: 4.7244 - val_accuracy: 0.1903
Epoch 14/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0830 - accuracy: 0.9789 - val_loss: 4.2263 - val_accuracy: 0.1903
Epoch 15/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0765 - accuracy: 0.9789 - val_loss: 3.8204 - val_accuracy: 0.1903
Epoch 16/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0711 - accuracy: 0.9789 - val_loss: 3.5063 - val_accuracy: 0.1903
Epoch 17/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0668 - accuracy: 0.9789 - val_loss: 3.2464 - val_accuracy: 0.1903
Epoch 18/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0632 - accuracy: 0.9789 - val_loss: 3.0247 - val_accuracy: 0.2569
Epoch 19/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0600 - accuracy: 0.9789 - val_loss: 2.8277 - val_accuracy: 0.3262
Epoch 20/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0570 - accuracy: 0.9789 - val_loss: 2.6524 - val_accuracy: 0.3282
Epoch 21/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0547 - accuracy: 0.9789 - val_loss: 2.4887 - val_accuracy: 0.3314
Epoch 22/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0529 - accuracy: 0.9789 - val_loss: 2.3332 - val_accuracy: 0.3487
Epoch 23/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0509 - accuracy: 0.9789 - val_loss: 2.1807 - val_accuracy: 0.3663
Epoch 24/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0490 - accuracy: 0.9790 - val_loss: 2.0424 - val_accuracy: 0.3894
Epoch 25/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0475 - accuracy: 0.9790 - val_loss: 1.9112 - val_accuracy: 0.4063
Epoch 26/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0459 - accuracy: 0.9793 - val_loss: 1.7915 - val_accuracy: 0.4241
Epoch 27/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0447 - accuracy: 0.9799 - val_loss: 1.6724 - val_accuracy: 0.4331
Epoch 28/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0434 - accuracy: 0.9807 - val_loss: 1.5596 - val_accuracy: 0.4507
Epoch 29/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0424 - accuracy: 0.9824 - val_loss: 1.4548 - val_accuracy: 0.4566
Epoch 30/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0411 - accuracy: 0.9835 - val_loss: 1.3589 - val_accuracy: 0.4691
Epoch 31/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0403 - accuracy: 0.9850 - val_loss: 1.2658 - val_accuracy: 0.4873
Epoch 32/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0394 - accuracy: 0.9865 - val_loss: 1.1789 - val_accuracy: 0.5046
Epoch 33/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0382 - accuracy: 0.9873 - val_loss: 1.1002 - val_accuracy: 0.5149
Epoch 34/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0375 - accuracy: 0.9886 - val_loss: 1.0240 - val_accuracy: 0.5286
Epoch 35/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0369 - accuracy: 0.9892 - val_loss: 0.9568 - val_accuracy: 0.5389
Epoch 36/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0360 - accuracy: 0.9898 - val_loss: 0.8930 - val_accuracy: 0.5474
Epoch 37/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0352 - accuracy: 0.9902 - val_loss: 0.8345 - val_accuracy: 0.5544
Epoch 38/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0345 - accuracy: 0.9906 - val_loss: 0.7813 - val_accuracy: 0.5669
Epoch 39/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 0.7314 - val_accuracy: 0.5961
Epoch 40/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0334 - accuracy: 0.9913 - val_loss: 0.6871 - val_accuracy: 0.8298
Epoch 41/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0326 - accuracy: 0.9914 - val_loss: 0.6457 - val_accuracy: 0.8346
Epoch 42/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0321 - accuracy: 0.9918 - val_loss: 0.6092 - val_accuracy: 0.8386
Epoch 43/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0317 - accuracy: 0.9918 - val_loss: 0.5758 - val_accuracy: 0.8425
Epoch 44/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0309 - accuracy: 0.9920 - val_loss: 0.5448 - val_accuracy: 0.8476
Epoch 45/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0307 - accuracy: 0.9923 - val_loss: 0.5165 - val_accuracy: 0.8532
Epoch 46/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0300 - accuracy: 0.9924 - val_loss: 0.4920 - val_accuracy: 0.8591
Epoch 47/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.4695 - val_accuracy: 0.8628
Epoch 48/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0293 - accuracy: 0.9926 - val_loss: 0.4491 - val_accuracy: 0.8666
Epoch 49/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0286 - accuracy: 0.9928 - val_loss: 0.4288 - val_accuracy: 0.8711
Epoch 50/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0283 - accuracy: 0.9928 - val_loss: 0.4114 - val_accuracy: 0.8754
Epoch 51/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0277 - accuracy: 0.9930 - val_loss: 0.3943 - val_accuracy: 0.8809
Epoch 52/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0277 - accuracy: 0.9929 - val_loss: 0.3783 - val_accuracy: 0.8884
Epoch 53/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0270 - accuracy: 0.9932 - val_loss: 0.3639 - val_accuracy: 0.8971
Epoch 54/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0268 - accuracy: 0.9932 - val_loss: 0.3509 - val_accuracy: 0.9005
Epoch 55/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0267 - accuracy: 0.9934 - val_loss: 0.3375 - val_accuracy: 0.9039
Epoch 56/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0260 - accuracy: 0.9934 - val_loss: 0.3263 - val_accuracy: 0.9068
Epoch 57/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.3158 - val_accuracy: 0.9091
Epoch 58/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0253 - accuracy: 0.9937 - val_loss: 0.3050 - val_accuracy: 0.9114
Epoch 59/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0251 - accuracy: 0.9937 - val_loss: 0.2961 - val_accuracy: 0.9134
Epoch 60/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0250 - accuracy: 0.9937 - val_loss: 0.2870 - val_accuracy: 0.9160
Epoch 61/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0244 - accuracy: 0.9938 - val_loss: 0.2775 - val_accuracy: 0.9178
Epoch 62/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 0.2705 - val_accuracy: 0.9191
Epoch 63/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0238 - accuracy: 0.9940 - val_loss: 0.2630 - val_accuracy: 0.9208
Epoch 64/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0237 - accuracy: 0.9941 - val_loss: 0.2563 - val_accuracy: 0.9226
Epoch 65/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.2496 - val_accuracy: 0.9245
Epoch 66/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0230 - accuracy: 0.9942 - val_loss: 0.2430 - val_accuracy: 0.9265
Epoch 67/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0230 - accuracy: 0.9940 - val_loss: 0.2373 - val_accuracy: 0.9286
Epoch 68/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 0.2325 - val_accuracy: 0.9305
Epoch 69/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0224 - accuracy: 0.9943 - val_loss: 0.2271 - val_accuracy: 0.9329
Epoch 70/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0223 - accuracy: 0.9945 - val_loss: 0.2222 - val_accuracy: 0.9355
Epoch 71/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0220 - accuracy: 0.9945 - val_loss: 0.2176 - val_accuracy: 0.9383
Epoch 72/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0219 - accuracy: 0.9945 - val_loss: 0.2138 - val_accuracy: 0.9411
Epoch 73/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0215 - accuracy: 0.9947 - val_loss: 0.2102 - val_accuracy: 0.9440
Epoch 74/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0213 - accuracy: 0.9946 - val_loss: 0.2070 - val_accuracy: 0.9480
Epoch 75/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0214 - accuracy: 0.9946 - val_loss: 0.2035 - val_accuracy: 0.9514
Epoch 76/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.2002 - val_accuracy: 0.9524
Epoch 77/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0206 - accuracy: 0.9948 - val_loss: 0.1970 - val_accuracy: 0.9534
Epoch 78/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0203 - accuracy: 0.9948 - val_loss: 0.1943 - val_accuracy: 0.9543
Epoch 79/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.1922 - val_accuracy: 0.9551
Epoch 80/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0199 - accuracy: 0.9949 - val_loss: 0.1900 - val_accuracy: 0.9559
Epoch 81/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0194 - accuracy: 0.9949 - val_loss: 0.1876 - val_accuracy: 0.9569
Epoch 82/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0198 - accuracy: 0.9949 - val_loss: 0.1859 - val_accuracy: 0.9575
Epoch 83/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.1837 - val_accuracy: 0.9584
Epoch 84/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0192 - accuracy: 0.9950 - val_loss: 0.1820 - val_accuracy: 0.9594
Epoch 85/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.1802 - val_accuracy: 0.9604
Epoch 86/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.1791 - val_accuracy: 0.9613
Epoch 87/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.1786 - val_accuracy: 0.9619
Epoch 88/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.1772 - val_accuracy: 0.9629
Epoch 89/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.1764 - val_accuracy: 0.9637
Epoch 90/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.1756 - val_accuracy: 0.9645
Epoch 91/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.1751 - val_accuracy: 0.9653
Epoch 92/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.1748 - val_accuracy: 0.9662
Epoch 93/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.1750 - val_accuracy: 0.9678
Epoch 94/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.1753 - val_accuracy: 0.9692
Epoch 95/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.1756 - val_accuracy: 0.9709
Epoch 96/100
1667/1667 [==============================] - 5s 3ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.1764 - val_accuracy: 0.9738
Epoch 97/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.1768 - val_accuracy: 0.9765
Epoch 98/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.1773 - val_accuracy: 0.9767
Epoch 99/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.1783 - val_accuracy: 0.9772
Epoch 100/100
1667/1667 [==============================] - 4s 3ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.1785 - val_accuracy: 0.9776

Process finished with exit code 0